# ğŸ“¡ AT&T â€” SMS Spam Detector

DÃ©tection automatique des SMS **spam** vs **ham** pour protÃ©ger les clients dâ€™AT&T.  
Ce projet sâ€™appuie sur un **fine-tuning de BERT/DistilBERT** (HuggingFace Transformers) et met en avant les **bonnes mÃ©triques mÃ©tier** (Recall spam, F1 spam, Precision ham). Le livrable principal est un **notebook exÃ©cutable et prÃªt Ã  prÃ©senter** : `Projet.ipynb`.

---

## ğŸ“– Contexte

AT&T est un gÃ©ant des tÃ©lÃ©communications ; ses utilisateurs sont exposÃ©s Ã  des **SMS indÃ©sirables (spams)** qui nuisent Ã  la satisfaction et Ã  la sÃ©curitÃ© (phishing, liens frauduleux).  
Historiquement, le marquage des spams a Ã©tÃ© **manuel** â€” ce nâ€™est plus scalable.

**Objectif :** construire un **classifieur automatique** qui identifie un SMS comme **ham (lÃ©gitime)** ou **spam**, **uniquement Ã  partir du texte**.

## ğŸ¯ Objectifs & critÃ¨res de succÃ¨s

- Construire un pipeline **reproductible** : prÃ©processing â†’ entraÃ®nement â†’ Ã©valuation.
- Utiliser le **transfert learning** (BERT/DistilBERT) pour compenser la faible quantitÃ© de donnÃ©es.
- Rapporter des **mÃ©triques adaptÃ©es au risque mÃ©tier** :
  - **Recall (spam)** : ne pas laisser passer de spams (prioritÃ©).
  - **F1 (spam)** : Ã©quilibre prÃ©cision/rappel cÃ´tÃ© spam.
  - **Precision (ham)** : limiter les faux positifs (ne pas bloquer des messages lÃ©gitimes).

## ğŸ—‚ï¸ DonnÃ©es (schÃ©ma & conseils)

- Fichier CSV avec 2 colonnes :
  - `label` : valeur textuelle **"ham"** ou **"spam"**
  - `message` : contenu textuel du SMS  
- Si vous partez dâ€™un CSV type â€œSMS Spam Collectionâ€ (souvent `v1` / `v2`) :
  - renommez **`v1 â†’ label`** et **`v2 â†’ message`** avant lâ€™encodage.
- **Encodage des labels** : `ham â†’ 0`, `spam â†’ 1`.

ğŸ’¡ **Encodage & lecture robuste** :
- Le notebook utilise `chardet` pour dÃ©tecter lâ€™encodage si nÃ©cessaire.
- Supprimez les doublons et lignes vides pour Ã©viter les biais ou crashs.


## ğŸ§­ MÃ©thodologie (ce que fait le notebook)

1. **Chargement & prÃ©paration**
   - Lecture du CSV (`pandas`), renommage (`label`, `message`), nettoyage de base.
   - Encodage binaire des labels (`ham`=0, `spam`=1).
2. **Split train/test stratifiÃ©**
   - `train_test_split(..., stratify=labels, test_size=0.2, random_state=42)`.
   - **Pas de fuite** de donnÃ©es ; reproductibilitÃ© assurÃ©e.
3. **Tokenization (HuggingFace)**
   - `BertTokenizerFast` / `AutoTokenizer`, `max_length=128`, `truncation`, `padding`.
4. **ModÃ©lisation**
   - `BertForSequenceClassification` / `AutoModelForSequenceClassification` (2 classes).
   - TÃªte de classification binaire.
5. **EntraÃ®nement (Trainer)**
   - `TrainingArguments`: `epochs=3`, `batch_size=8-16`, `lrâ‰ˆ2e-5`, `evaluation_strategy="epoch"`, `load_best_model_at_end=True`.
6. **Ã‰valuation**
   - `classification_report` (precision/recall/F1 par classe).
   - `confusion_matrix` (lecture FN/FP).
   - Visualisations (seaborn/matplotlib).
7. **(Optionnel) Sauvegarde**
   - `save_pretrained` pour le modÃ¨le et le tokenizer (dÃ©ploiement possible).


## ğŸ“Š InterprÃ©tation des mÃ©triques

- **Recall (spam)** â†‘ : **critique** pour ne pas laisser passer de spams.
- **Precision (ham)** : Ã©viter de bloquer des messages lÃ©gitimes.
- **F1 (spam)** : bonne synthÃ¨se de performance sur la classe Ã  risque.

> Rappel lecture matrice de confusion :
> - **FN (spamâ†’ham)** : *spams manquÃ©s* (âš ï¸ risque).
> - **FP (hamâ†’spam)** : *hams bloquÃ©s* (gÃªne utilisateur).


## ğŸ” ReproductibilitÃ©

- **Seeds** fixÃ©s (`random_state=42`, seeds torch si GPU dispo).
- **Split stratifiÃ©** conservant la proportion spam/ham.
- **Ã‰valuation sur jeu de test** strictement tenu Ã  lâ€™Ã©cart pendant lâ€™entraÃ®nement.


## âš™ï¸ Installation

```bash
python -m venv .venv
# Linux/Mac
source .venv/bin/activate
# Windows
.venv\Scripts\activate

pip install -r requirements.txt


